---
title: "Dataset"
output: pdf_document
date: "2025-01-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Install the jsonlite package
install.packages("jsonlite")

install.packages("dplyr")
library(dplyr)

# Load the jsonlite package
library(jsonlite)

# Read the JSON file into R
amazon_tweet <- fromJSON("amazon.json")
apple_tweet <- fromJSON("apple.json")
facebook_tweet <- fromJSON("facebook.json")
google_tweet <- fromJSON("google.json")
```

```{r}



# Remove the 'id' column from all datasets
amazon_tweet <- amazon_tweet %>% select(-id)
apple_tweet <- apple_tweet %>% select(-id)
facebook_tweet <- facebook_tweet %>% select(-id)
google_tweet <- google_tweet %>% select(-id)
```

```{r}
# Check the structure of the loaded data
str(amazon_tweet)
```
```{r}
# Convert the large numeric date (Unix timestamp in milliseconds) to a readable date format
amazon_tweet$date <- as.POSIXct(amazon_tweet$date / 1000, origin = "1970-01-01", tz = "UTC")
apple_tweet$date <- as.POSIXct(apple_tweet$date / 1000, origin = "1970-01-01", tz = "UTC")
facebook_tweet$date <- as.POSIXct(facebook_tweet$date / 1000, origin = "1970-01-01", tz = "UTC")
google_tweet$date <- as.POSIXct(google_tweet$date / 1000, origin = "1970-01-01", tz = "UTC")

```

```{r}
# Convert the 'date' column to a readable date format
amazon_tweet$date <- format(as.Date(amazon_tweet$date), "%Y-%m-%d")
apple_tweet$date <- format(as.Date(apple_tweet$date), "%Y-%m-%d")
facebook_tweet$date <- format(as.Date(facebook_tweet$date), "%Y-%m-%d")
google_tweet$date <- format(as.Date(google_tweet$date), "%Y-%m-%d")



```





```{r}
# Assign Sentiment variable


amazon_sentiment <- c("Neutral", "Neutral", "Negative", "Negative", "Positive", "Negative", "Negative", "Negative", "Positive", "Negative",
                
"Neutral","Negative", "Negative", "Negative", "Negative", "Negative", "Negative", "Negative", "Neutral", "Neutral",

"Neutral", "Neutral", "Negative", "Negative", "Negative", "Negative", "Negative", "Positive", "Positive", "Negative", 

"Negative", "Negative", "Negative", "Negative", "Negative", "Negative", "Negative", "Negative", "Negative", "Negative",

"Negative", "Negative", "Negative", "Negative", "Negative", "Negative")

apple_sentiment <- c("Neutral", "Neutral","Positive", "Negative", "Negative", "Positive", "Positive", "Neutral", "Positive", "Positive", 
                     
  "Positive", "Negative", "Negative", "Neutral", "Neutral", "Neutral", "Negative", "Positive", "Neutral", "Positive", 
  
  "Positive")

facebook_sentiment <- c("Neutral", "Neutral","Negative", "Negative", "Negative", "Negative", "Negative", "Negative", "Negative", "Neutral", 
                        
"Negative", "Neutral", "Positive", "Neutral", "Neutral", "Positive", "Negative", "Negative", "Neutral", "Negative",

"Negative","Negative", "Negative", "Negative", "Negative", "Negative", "Negative", "Negative", "Neutral", "Neutral",

"Negative", "Negative", "Negative", "Negative", "Negative", "Positive","Negative" )

google_sentiment <- c("Negative", "Negative", "Neutral", "Neutral", "Negative", "Negative", "Negative", "Negative", "Positive", "Negative", 
                      
"Negative", "Negative", "Negative", "Negative", "Neutral", "Negative", "Negative", "Negative", "Neutral", "Negative",

"Negative", "Negative", "Positive", "Positive", "Negative", "Negative", "Negative", "Negative", "Neutral", "Positive",

"Negative", "Negative", "Negative", "Negative", "Negative")


# Convert Sentiment Values into Tweet data
amazon_tweet$Sentiment <- amazon_sentiment
apple_tweet$Sentiment <- apple_sentiment
facebook_tweet$Sentiment <- facebook_sentiment
google_tweet$Sentiment <- google_sentiment 

# Convert the sentiment labels to numerical values: 
# 1 for Positive, 0 for Neutral, and -1 for Negative
amazon_tweet$Sentiment <- ifelse(amazon_tweet$Sentiment == "Positive", 1,
                                 ifelse(amazon_tweet$Sentiment == "Neutral", 0, -1))

apple_tweet$Sentiment <- ifelse(apple_tweet$Sentiment == "Positive", 1,
                                ifelse(apple_tweet$Sentiment == "Neutral", 0, -1))

facebook_tweet$Sentiment <- ifelse(facebook_tweet$Sentiment == "Positive", 1,
                                   ifelse(facebook_tweet$Sentiment == "Neutral", 0, -1))

google_tweet$Sentiment <- ifelse(google_tweet$Sentiment == "Positive", 1,
                                 ifelse(google_tweet$Sentiment == "Neutral", 0, -1))

```


##
# Save the data frame to a CSV file
write.csv(amazon_data, "amazon_tweets.csv", row.names = FALSE)
write.csv(apple_data, "apple_tweets.csv", row.names = FALSE)


```{r}
# Load necessary libraries
library(tidyquant)
library(dplyr)
library(tidyr)
library(lubridate)

# Define a function to get stock data and process it
get_stock_data <- function(ticker, start_date, end_date) {
  stock_data <- tq_get(ticker, from = start_date, to = end_date) %>%
    dplyr::select(symbol, date, adjusted) %>%
    tidyr::pivot_wider(names_from = symbol, values_from = adjusted) %>%
    group_by(week = floor_date(date, "week")) %>%
    summarize(price = mean(get(ticker), na.rm = TRUE))  # Calculate weekly average price
  
  # Convert time series data into a data frame for easier viewing
  return(data.frame(week = stock_data$week, price = stock_data$price))
}

# Set date range for Trump's presidency
start_date <- "2017-01-20"
end_date <- "2021-01-20"

# Get stock data for each company
apple_stock <- get_stock_data("AAPL", start_date, end_date)
amazon_stock <- get_stock_data("AMZN", start_date, end_date)
facebook_stock <- get_stock_data("META", start_date, end_date) 
google_stock <- get_stock_data("GOOGL", start_date, end_date)



```


amazon, * 46 tweets/rt
apple, * 21 tweets/rt

facebook ,* 37 tweets/rt

Google * 35 tweets/rt



```{r}
library(dplyr)
library(lubridate)

# Convert the date column in amazon_tweet to Date format
amazon_merged_data <- amazon_tweet %>%
  mutate(date = as.Date(date, format = "%Y-%m-%d")) %>%
  # Add a 'week' column for each tweet based on its 'date'
  mutate(week = floor_date(date, unit = "week")) %>%
  # Join the tweet data with the stock data by the week
  left_join(amazon_stock %>%
              mutate(week = as.Date(week, format = "%Y-%m-%d")), 
            by = "week")

# View the result
head(amazon_merged_data)


```

```{r}
# Assuming amazon_tweet has the sentiment and date columns
library(ggplot2)

# Ensure that 'date' is in Date format (if it's not already)
amazon_tweet$date <- as.Date(amazon_tweet$date)

# Create the line plot
sentiment_plot <- ggplot(amazon_tweet, aes(x = date, y = Sentiment)) +
  geom_line(color = "blue") +  # Line plot of sentiment scores
  geom_point(color = "red", size = 2) +  # Points to highlight sentiment changes
  ggtitle("Sentiment Score Over Time") +
  xlab("Date") +  # Use 'Date' for clarity
  ylab("Sentiment") + 
  scale_y_continuous(breaks = c(-1, 0, 1), labels = c("Negative", "Neutral", "Positive")) +  # Adjust labels
  theme_minimal()  # Clean theme


# Frequency of Each Sentiment Plot
sentiment_frequency <- amazon_tweet %>%
  count(Sentiment) %>%
  mutate(Sentiment = factor(Sentiment, levels = c(-1, 0, 1), labels = c("Negative", "Neutral", "Positive")))

frequency_plot <- ggplot(sentiment_frequency, aes(x = Sentiment, y = n, fill = Sentiment)) +
  geom_bar(stat = "identity") +  # Bar plot of sentiment frequencies
  ggtitle("Sentiment Frequency") +
  xlab("Sentiment") + 
  ylab("Frequency") +
  theme_minimal()

# Display both plots side by side
library(gridExtra)
grid.arrange(sentiment_plot, frequency_plot, ncol = 2)
```



Correlation
```{r}
# Correlation between sentiment and stock price
cor(amazon_merged_data$Sentiment, amazon_merged_data$price)

```

VAR
```{r}
library(vars)

# Assuming weekly_data contains both sentiment and stock price columns
weekly_ts <- ts(amazon_merged_data[, c("Sentiment", "price")], start = c(2017, 1), frequency = 52)

# Fit VAR model with 2 lags
var_model <- VAR(weekly_ts, p = 2)
summary(var_model)

# Check causality from sentiment to stock price
causality(var_model, cause = "Sentiment")
```

```{r}
amazon_merged_data = amazon_merged_data %>% mutate(price_change = price - lag(price, 1),
                                                   sent_2 = Sentiment - lag(Sentiment,1),
                                                   favorites = as.numeric(favorites))

# Fit the linear model with Sentiment as the predictor for price change
lm_model <- lm(price_change ~ Sentiment + sent_2 + week +favorites , 
               data = amazon_merged_data, 
               na.action = na.omit)

# Display model summary
summary(lm_model)


# Display model summary
summary(lm_model)
```

```{r}
forecast <- predict(var_model, n.ahead = 1)
print(forecast)
```


```{r}
library(ggplot2)

# Plot Amazon Stock Price
ggplot(amazon_stock, aes(x = week, y = price)) +
  geom_line(color = "blue") +
  labs(title = "Amazon Stock Price Over Time",
       x = "Date",
       y = "Stock Price (USD)") +
  theme_minimal()

# Plot Apple Stock Price
ggplot(apple_stock, aes(x = week, y = price)) +
  geom_line(color = "red") +
  labs(title = "Apple Stock Price Over Time",
       x = "Date",
       y = "Stock Price (USD)") +
  theme_minimal()

# Plot Facebook Stock Price
ggplot(facebook_stock, aes(x = week, y = price)) +
  geom_line(color = "green") +
  labs(title = "Facebook Stock Price Over Time",
       x = "Date",
       y = "Stock Price (USD)") +
  theme_minimal()

# Plot Google Stock Price
ggplot(google_stock, aes(x = week, y = price)) +
  geom_line(color = "purple") +
  labs(title = "Google Stock Price Over Time",
       x = "Date",
       y = "Stock Price (USD)") +
  theme_minimal()



```






